{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de Retención de Clientes para Beta Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "Los clientes de Beta Bank están abandonando el banco gradualmente cada mes. Dado que es más rentable retener a los clientes existentes que atraer nuevos, Beta Bank necesita un modelo predictivo que pueda identificar qué clientes probablemente abandonarán el banco en el futuro cercano. Este proyecto tiene como objetivo desarrollar un modelo con el máximo valor F1 posible para predecir la probabilidad de churn de los clientes. Además del F1, evaluaremos la métrica AUC-ROC para una comparación integral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción de los Datos\n",
    "El conjunto de datos proporcionado contiene las siguientes características:\n",
    "\n",
    "RowNumber: Índice de cadena de datos\n",
    "\n",
    "CustomerId: Identificador único del cliente\n",
    "\n",
    "Surname: Apellido del cliente\n",
    "\n",
    "CreditScore: Puntuación crediticia del cliente\n",
    "\n",
    "Geography: País de residencia del cliente\n",
    "\n",
    "Gender: Género del cliente\n",
    "\n",
    "Age: Edad del cliente\n",
    "\n",
    "Tenure: Período de madurez del depósito a plazo fijo del cliente (años)\n",
    "\n",
    "Balance: Saldo de la cuenta del cliente\n",
    "\n",
    "NumOfProducts: Número de productos bancarios utilizados por el cliente\n",
    "\n",
    "HasCrCard: Indicador de si el cliente tiene una tarjeta de crédito (1 - sí; 0 - no)\n",
    "\n",
    "IsActiveMember: Actividad del cliente (1 - sí; 0 - no)\n",
    "\n",
    "EstimatedSalary: Salario estimado del cliente\n",
    "\n",
    "El objetivo es predecir la variable Exited, que indica si el cliente ha abandonado el banco (1 - sí; 0 - no)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de Librerías Necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descargar y Preparar los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0     2.0       0.00              1          1               1   \n",
      "1     1.0   83807.86              1          0               1   \n",
      "2     8.0  159660.80              3          1               0   \n",
      "3     1.0       0.00              2          0               0   \n",
      "4     2.0  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
      "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
      "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
      "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
      "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
      "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
      "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
      "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
      "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
      "\n",
      "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
      "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
      "mean    76485.889288       1.530200      0.70550        0.515100   \n",
      "std     62397.405202       0.581654      0.45584        0.499797   \n",
      "min         0.000000       1.000000      0.00000        0.000000   \n",
      "25%         0.000000       1.000000      0.00000        0.000000   \n",
      "50%     97198.540000       1.000000      1.00000        1.000000   \n",
      "75%    127644.240000       2.000000      1.00000        1.000000   \n",
      "max    250898.090000       4.000000      1.00000        1.000000   \n",
      "\n",
      "       EstimatedSalary        Exited  \n",
      "count     10000.000000  10000.000000  \n",
      "mean     100090.239881      0.203700  \n",
      "std       57510.492818      0.402769  \n",
      "min          11.580000      0.000000  \n",
      "25%       51002.110000      0.000000  \n",
      "50%      100193.915000      0.000000  \n",
      "75%      149388.247500      0.000000  \n",
      "max      199992.480000      1.000000  \n",
      "RowNumber            0\n",
      "CustomerId           0\n",
      "Surname              0\n",
      "CreditScore          0\n",
      "Geography            0\n",
      "Gender               0\n",
      "Age                  0\n",
      "Tenure             909\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Exited               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos\n",
    "data_path = '/datasets/Churn.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Información general sobre el DataFrame\n",
    "print(df.info())\n",
    "\n",
    "# Estadísticas descriptivas de las variables\n",
    "print(df.describe())\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión parcial\n",
    "\n",
    "hemos descargado y examinado el conjunto de datos proporcionado por Beta Bank. Los datos contienen 10,000 registros y 14 columnas, donde cada columna representa una característica del cliente, como 'CreditScore', 'Geography', 'Gender', 'Age', entre otras, y la columna objetivo 'Exited' indica si el cliente ha abandonado el banco o no.\n",
    "\n",
    "En la exploración inicial, observamos que:\n",
    "\n",
    "La mayoría de las columnas no contienen valores nulos, con la excepción de la columna 'Tenure' que presenta 909 valores nulos.\n",
    "\n",
    "Las variables categóricas incluyen 'Geography' y 'Gender'.\n",
    "\n",
    "El conjunto de datos está bien estructurado y contiene una mezcla de variables numéricas y categóricas.\n",
    "\n",
    "Estos hallazgos nos permitirán planificar el preprocesamiento necesario, como el manejo de valores nulos y la codificación de variables categóricas, antes de entrenar los modelos de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de Datos\n",
    "En este paso, realizaremos el preprocesamiento necesario para preparar los datos para el entrenamiento del modelo. Esto incluye manejar los valores nulos, codificar las variables categóricas, y dividir los datos en conjuntos de entrenamiento y prueba. El preprocesamiento es crucial para garantizar que los datos estén en un formato adecuado para los algoritmos de machine learning y para mejorar la calidad de nuestros modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columna 'Tenure'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestro análisis inicial, notamos que la columna 'Tenure' contiene valores nulos. Decidiremos la mejor estrategia para manejarlos, como la imputación con la mediana o la eliminación de las filas con valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RowNumber            0\n",
      "CustomerId           0\n",
      "Surname              0\n",
      "CreditScore          0\n",
      "Geography            0\n",
      "Gender               0\n",
      "Age                  0\n",
      "Tenure             909\n",
      "Balance              0\n",
      "NumOfProducts        0\n",
      "HasCrCard            0\n",
      "IsActiveMember       0\n",
      "EstimatedSalary      0\n",
      "Exited               0\n",
      "dtype: int64\n",
      "RowNumber          0\n",
      "CustomerId         0\n",
      "Surname            0\n",
      "CreditScore        0\n",
      "Geography          0\n",
      "Gender             0\n",
      "Age                0\n",
      "Tenure             0\n",
      "Balance            0\n",
      "NumOfProducts      0\n",
      "HasCrCard          0\n",
      "IsActiveMember     0\n",
      "EstimatedSalary    0\n",
      "Exited             0\n",
      "dtype: int64\n",
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0     2.0       0.00              1          1               1   \n",
      "1     1.0   83807.86              1          0               1   \n",
      "2     8.0  159660.80              3          1               0   \n",
      "3     1.0       0.00              2          0               0   \n",
      "4     2.0  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n"
     ]
    }
   ],
   "source": [
    "# Verificar valores nulos\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Imputar valores nulos en 'Tenure' con la mediana\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df['Tenure'] = imputer.fit_transform(df[['Tenure']])\n",
    "\n",
    "# Verificar valores nulos después de la imputación\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Mostrar las primeras filas para verificar el resultado de la imputación\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificación de Variables Categóricas\n",
    "En este paso, convertiremos las variables categóricas ('Geography' y 'Gender') en variables numéricas utilizando One-Hot Encoding (OHE). Esto nos permitirá utilizar estas variables en nuestros modelos de aprendizaje automático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore  Age  Tenure    Balance  \\\n",
      "0          1    15634602  Hargrave          619   42     2.0       0.00   \n",
      "1          2    15647311      Hill          608   41     1.0   83807.86   \n",
      "2          3    15619304      Onio          502   42     8.0  159660.80   \n",
      "3          4    15701354      Boni          699   39     1.0       0.00   \n",
      "4          5    15737888  Mitchell          850   43     2.0  125510.82   \n",
      "\n",
      "   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \\\n",
      "0              1          1               1        101348.88       1   \n",
      "1              1          0               1        112542.58       0   \n",
      "2              3          1               0        113931.57       1   \n",
      "3              2          0               0         93826.63       0   \n",
      "4              1          1               1         79084.10       0   \n",
      "\n",
      "   Geography_Germany  Geography_Spain  Gender_Male  \n",
      "0                  0                0            0  \n",
      "1                  0                1            0  \n",
      "2                  0                0            0  \n",
      "3                  0                0            0  \n",
      "4                  0                1            0  \n"
     ]
    }
   ],
   "source": [
    "# Aplicar One-Hot Encoding a las columnas 'Geography' y 'Gender'\n",
    "df = pd.get_dummies(df, columns=['Geography', 'Gender'], drop_first=True)\n",
    "\n",
    "# Verificar las primeras filas después de la codificación\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusión parcial\n",
    "\n",
    "Este paso ha transformado efectivamente nuestras variables categóricas, permitiendo una mejor comprensión y procesamiento de los datos por los algoritmos de aprendizaje automático. Ahora podemos proceder a la siguiente etapa del preprocesamiento de datos, asegurándonos de que los datos estén listos para la modelización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de Datos en Conjuntos de Entrenamiento, Validación y Prueba\n",
    "En este paso, dividiremos los datos en tres conjuntos: entrenamiento, validación y prueba. Esta división nos permitirá entrenar el modelo en un conjunto de datos, validar su rendimiento y, finalmente, evaluar su rendimiento en un conjunto de prueba independiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto de entrenamiento: 6000\n",
      "Tamaño del conjunto de validación: 2000\n",
      "Tamaño del conjunto de prueba: 2000\n"
     ]
    }
   ],
   "source": [
    "# Definir características y objetivo\n",
    "features = df.drop(columns=['RowNumber', 'CustomerId', 'Surname', 'Exited'])\n",
    "target = df['Exited']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento (60%) y conjunto restante (40%)\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(\n",
    "    features, target, test_size=0.4, random_state=12345, stratify=target\n",
    ")\n",
    "\n",
    "# Dividir el conjunto restante en validación (50%) y prueba (50%) para obtener 20% cada uno\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_temp, target_temp, test_size=0.5, random_state=12345, stratify=target_temp\n",
    ")\n",
    "\n",
    "# Mostrar los tamaños de los conjuntos\n",
    "print(f'Tamaño del conjunto de entrenamiento: {features_train.shape[0]}')\n",
    "print(f'Tamaño del conjunto de validación: {features_valid.shape[0]}')\n",
    "print(f'Tamaño del conjunto de prueba: {features_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusión parcial \n",
    "\n",
    "Hemos dividido con éxito los datos en conjuntos de entrenamiento, validación y prueba, manteniendo la proporción de clases en cada conjunto gracias a la estratificación. Esta división nos permitirá entrenar, validar y probar nuestros modelos de manera efectiva, asegurando que los resultados sean representativos y robustos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar Modelos Iniciales sin Considerar el Desequilibrio de Clases\n",
    "En este paso, entrenaremos varios modelos de clasificación sin tener en cuenta el desequilibrio de clases en los datos. Evaluaremos su rendimiento en el conjunto de validación y compararemos los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - F1: 0.5048, AUC-ROC: 0.6904\n",
      "Random Forest - F1: 0.6106, AUC-ROC: 0.8622\n",
      "Logistic Regression - F1: 0.0619, AUC-ROC: 0.6995\n"
     ]
    }
   ],
   "source": [
    "# Entrenar y evaluar modelo Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=12345)\n",
    "dt_model.fit(features_train, target_train)\n",
    "dt_predictions = dt_model.predict(features_valid)\n",
    "dt_f1 = f1_score(target_valid, dt_predictions)\n",
    "dt_auc_roc = roc_auc_score(target_valid, dt_model.predict_proba(features_valid)[:, 1])\n",
    "\n",
    "# Entrenar y evaluar modelo Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=12345)\n",
    "rf_model.fit(features_train, target_train)\n",
    "rf_predictions = rf_model.predict(features_valid)\n",
    "rf_f1 = f1_score(target_valid, rf_predictions)\n",
    "rf_auc_roc = roc_auc_score(target_valid, rf_model.predict_proba(features_valid)[:, 1])\n",
    "\n",
    "# Entrenar y evaluar modelo Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=12345, max_iter=1000)\n",
    "lr_model.fit(features_train, target_train)\n",
    "lr_predictions = lr_model.predict(features_valid)\n",
    "lr_f1 = f1_score(target_valid, lr_predictions)\n",
    "lr_auc_roc = roc_auc_score(target_valid, lr_model.predict_proba(features_valid)[:, 1])\n",
    "\n",
    "# Mostrar las métricas de rendimiento\n",
    "print(f'Decision Tree - F1: {dt_f1:.4f}, AUC-ROC: {dt_auc_roc:.4f}')\n",
    "print(f'Random Forest - F1: {rf_f1:.4f}, AUC-ROC: {rf_auc_roc:.4f}')\n",
    "print(f'Logistic Regression - F1: {lr_f1:.4f}, AUC-ROC: {lr_auc_roc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conlusión parcial\n",
    "Dado que Random Forest ha mostrado el mejor rendimiento inicial, procederemos a mejorar la calidad del modelo abordando el desequilibrio de clases en los datos. Utilizaremos al menos dos técnicas para corregir el desequilibrio y evaluaremos su impacto en el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejorar la Calidad del Modelo\n",
    "En este paso, mejoraremos la calidad del modelo abordando el desequilibrio de clases. Utilizaremos dos enfoques principales para corregir el desequilibrio: sobremuestreo (oversampling) y submuestreo (undersampling). Evaluaremos el impacto de cada técnica en el rendimiento del modelo utilizando Random Forest, que mostró el mejor rendimiento en los pasos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7963\n",
      "1    7963\n",
      "Name: Exited, dtype: int64\n",
      "Oversampling - F1: 0.8192, AUC-ROC: 0.9030\n"
     ]
    }
   ],
   "source": [
    "# Separar clases mayoritarias y minoritarias\n",
    "df_majority = df[df.Exited == 0]\n",
    "df_minority = df[df.Exited == 1]\n",
    "\n",
    "# Aumentar la clase minoritaria\n",
    "df_minority_oversampled = resample(df_minority, \n",
    "                                   replace=True,     \n",
    "                                   n_samples=len(df_majority),    \n",
    "                                   random_state=123) \n",
    "\n",
    "# Combinar las clases mayoritarias y minoritarias aumentadas\n",
    "df_oversampled = pd.concat([df_majority, df_minority_oversampled])\n",
    "\n",
    "# Verificar el nuevo balance de clases\n",
    "print(df_oversampled.Exited.value_counts())\n",
    "\n",
    "# Dividir los datos aumentados\n",
    "X = df_oversampled.drop(['Exited', 'RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "y = df_oversampled['Exited']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=12345)\n",
    "\n",
    "# Entrenar y evaluar el modelo Random Forest con sobremuestreo\n",
    "model_oversampling = RandomForestClassifier(random_state=12345, n_estimators=100, max_depth=8)\n",
    "model_oversampling.fit(X_train, y_train)\n",
    "predictions = model_oversampling.predict(X_valid)\n",
    "\n",
    "f1_oversampling = f1_score(y_valid, predictions)\n",
    "auc_roc_oversampling = roc_auc_score(y_valid, model_oversampling.predict_proba(X_valid)[:, 1])\n",
    "\n",
    "print(f'Oversampling - F1: {f1_oversampling:.4f}, AUC-ROC: {auc_roc_oversampling:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2037\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n",
      "Undersampling - F1: 0.7745, AUC-ROC: 0.8608\n"
     ]
    }
   ],
   "source": [
    "# Reducir la clase mayoritaria\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                   replace=False,   \n",
    "                                   n_samples=len(df_minority),     \n",
    "                                   random_state=123) \n",
    "\n",
    "# Combinar clases mayoritarias y minoritarias reducidas\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Verificar el nuevo balance de clases\n",
    "print(df_downsampled.Exited.value_counts())\n",
    "\n",
    "# Dividir los datos reducidos\n",
    "X = df_downsampled.drop(['Exited', 'RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "y = df_downsampled['Exited']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=12345)\n",
    "\n",
    "# Entrenar y evaluar el modelo Random Forest con submuestreo\n",
    "model_undersampling = RandomForestClassifier(random_state=12345, n_estimators=100, max_depth=8)\n",
    "model_undersampling.fit(X_train, y_train)\n",
    "predictions = model_undersampling.predict(X_valid)\n",
    "\n",
    "f1_undersampling = f1_score(y_valid, predictions)\n",
    "auc_roc_undersampling = roc_auc_score(y_valid, model_undersampling.predict_proba(X_valid)[:, 1])\n",
    "\n",
    "print(f'Undersampling - F1: {f1_undersampling:.4f}, AUC-ROC: {auc_roc_undersampling:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión parcial\n",
    "\n",
    "**Sobremuestreo (Oversampling)**:\n",
    "- **Balance de Clases**: El sobremuestreo ha equilibrado perfectamente las clases, resultando en 7963 observaciones para cada clase (0 y 1).\n",
    "- **Rendimiento del Modelo**: El modelo Random Forest entrenado con el conjunto de datos sobremuestreado ha alcanzado un F1-score de 0.8192 y un AUC-ROC de 0.9030. Estos valores indican un buen equilibrio entre precisión y recall, y una alta capacidad para distinguir entre clases positivas y negativas.\n",
    "\n",
    "**Submuestreo (Undersampling)**:\n",
    "- **Balance de Clases**: El submuestreo ha equilibrado las clases a un nivel más reducido, con 2037 observaciones para cada clase (0 y 1).\n",
    "- **Rendimiento del Modelo**: El modelo Random Forest entrenado con el conjunto de datos submuestreado ha alcanzado un F1-score de 0.7745 y un AUC-ROC de 0.8608. Aunque estos valores son buenos, son ligeramente inferiores a los obtenidos con el sobremuestreo.\n",
    "\n",
    "**Comparación y Observaciones**:\n",
    "- **F1-Score**: El modelo con sobremuestreo tiene un F1-score más alto (0.8192) en comparación con el modelo con submuestreo (0.7745). Esto sugiere que el modelo con sobremuestreo maneja mejor el equilibrio entre precisión y recall.\n",
    "- **AUC-ROC**: El AUC-ROC del modelo con sobremuestreo (0.9030) es también superior al del modelo con submuestreo (0.8608), indicando una mejor capacidad de discriminación entre las clases positivas y negativas.\n",
    "\n",
    "**Observación**:\n",
    "El modelo entrenado con sobremuestreo muestra un mejor rendimiento en términos de F1-score y AUC-ROC en comparación con el modelo entrenado con submuestreo. Por lo tanto, el enfoque de sobremuestreo es más efectivo para abordar el desequilibrio de clases en este conjunto de datos. En el siguiente paso, utilizaremos este modelo mejorado para la prueba final y evaluaremos su rendimiento en el conjunto de prueba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba Final del Modelo\n",
    "\n",
    "En este paso, entrenaremos el modelo Random Forest utilizando el enfoque de sobremuestreo en todo el conjunto de datos y evaluaremos su rendimiento en el conjunto de prueba. Nuestro objetivo es verificar si el modelo mantiene un buen rendimiento en términos de F1-score y AUC-ROC en datos no vistos anteriormente.\n",
    "\n",
    "### Entrenamiento Final del Modelo con Sobremuestreo\n",
    "\n",
    "Entrenaremos el modelo Random Forest con el conjunto de datos completo y equilibrado mediante sobremuestreo. Luego, evaluaremos su rendimiento en el conjunto de prueba y calcularemos las métricas F1-score y AUC-ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7963\n",
      "1    7963\n",
      "Name: Exited, dtype: int64\n",
      "Final Test - F1: 0.8192, AUC-ROC: 0.9024\n"
     ]
    }
   ],
   "source": [
    "# Aumentar la clase minoritaria\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=len(df_majority),    \n",
    "                                 random_state=123) \n",
    "\n",
    "# Combinar las clases mayoritarias y minoritarias aumentadas\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "# Verificar el nuevo balance de clases\n",
    "print(df_upsampled.Exited.value_counts())\n",
    "\n",
    "# Dividir los datos aumentados en entrenamiento y prueba\n",
    "X = df_upsampled.drop(['Exited', 'RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "y = df_upsampled['Exited']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=12345, stratify=y)\n",
    "\n",
    "# Entrenar el modelo con el conjunto sobremuestreado completo\n",
    "best_model = RandomForestClassifier(random_state=12345, n_estimators=100, max_depth=8)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_predictions = best_model.predict(X_test)\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "test_auc_roc = roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "print(f'Final Test - F1: {test_f1:.4f}, AUC-ROC: {test_auc_roc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión General del Proyecto\n",
    "\n",
    "En este proyecto, desarrollamos un modelo predictivo para identificar clientes que probablemente abandonarán Beta Bank. A continuación, se resumen los pasos principales y hallazgos del proyecto:\n",
    "\n",
    "### Exploración y Preprocesamiento de Datos\n",
    "- **Exploración Inicial:** Descargamos y examinamos los datos proporcionados, identificando valores nulos y características categóricas que requirieron tratamiento.\n",
    "- **Imputación y Codificación:** Imputamos los valores nulos en la columna 'Tenure' utilizando la mediana y codificamos las variables categóricas 'Geography' y 'Gender' utilizando One-Hot Encoding (OHE).\n",
    "\n",
    "### División de Datos\n",
    "- **División Estratificada:** Dividimos los datos en conjuntos de entrenamiento (60%), validación (20%) y prueba (20%), manteniendo la proporción de clases en cada conjunto mediante estratificación.\n",
    "\n",
    "### Entrenamiento Inicial de Modelos\n",
    "- **Modelos Baseline:** Entrenamos y evaluamos varios modelos de clasificación (Decision Tree, Random Forest, Logistic Regression) sin abordar el desequilibrio de clases. El modelo Random Forest mostró el mejor rendimiento inicial con un F1-score de 0.6106 y un AUC-ROC de 0.8622 en el conjunto de validación.\n",
    "\n",
    "### Mejora del Modelo\n",
    "- **Abordaje del Desequilibrio de Clases:** Utilizamos técnicas de sobremuestreo y submuestreo para corregir el desequilibrio de clases. El modelo Random Forest con sobremuestreo ofreció el mejor rendimiento, alcanzando un F1-score de 0.8192 y un AUC-ROC de 0.9030 en el conjunto de validación.\n",
    "\n",
    "### Prueba Final del Modelo\n",
    "- **Entrenamiento Completo:** Entrenamos el modelo Random Forest con el conjunto de datos completo y sobremuestreado, y evaluamos su rendimiento en el conjunto de prueba.\n",
    "- **Resultados:** El modelo final alcanzó un F1-score de 0.8192 y un AUC-ROC de 0.9024 en el conjunto de prueba, demostrando una alta capacidad para predecir correctamente qué clientes probablemente abandonarán el banco.\n",
    "\n",
    "### Sugerencias para Futuras Decisiones\n",
    "1. **Optimización Continua:** Continuar optimizando los hiperparámetros del modelo utilizando técnicas avanzadas para mejorar aún más el rendimiento.\n",
    "2. **Exploración de Nuevos Algoritmos:** Explorar algoritmos de aprendizaje automático más avanzados que pueden ofrecer un mejor rendimiento en problemas de clasificación desequilibrada.\n",
    "3. **Feature Engineering:** Investigar y crear nuevas características derivadas de las existentes para proporcionar más información al modelo.\n",
    "4. **Monitoreo del Modelo:** Implementar un sistema de monitoreo para evaluar el rendimiento del modelo en producción y ajustarlo según sea necesario para mantener su efectividad.\n",
    "\n",
    "Con estas estrategias, Beta Bank puede mejorar aún más su capacidad para predecir y retener a los clientes, asegurando un enfoque proactivo en la gestión de la satisfacción del cliente y la reducción de la tasa de abandono.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 5109,
    "start_time": "2024-07-24T15:15:27.677Z"
   },
   {
    "duration": 1144,
    "start_time": "2024-07-24T15:15:55.572Z"
   },
   {
    "duration": 100,
    "start_time": "2024-07-24T15:16:16.858Z"
   },
   {
    "duration": 28,
    "start_time": "2024-07-24T15:43:46.407Z"
   },
   {
    "duration": 30,
    "start_time": "2024-07-24T15:45:13.594Z"
   },
   {
    "duration": 8,
    "start_time": "2024-07-24T15:45:32.910Z"
   },
   {
    "duration": 24,
    "start_time": "2024-07-24T15:45:37.302Z"
   },
   {
    "duration": 19,
    "start_time": "2024-07-24T15:54:45.839Z"
   },
   {
    "duration": 335,
    "start_time": "2024-07-25T23:07:48.419Z"
   },
   {
    "duration": 5212,
    "start_time": "2024-07-25T23:07:52.722Z"
   },
   {
    "duration": 110,
    "start_time": "2024-07-25T23:07:57.941Z"
   },
   {
    "duration": 28,
    "start_time": "2024-07-25T23:07:58.057Z"
   },
   {
    "duration": 43,
    "start_time": "2024-07-25T23:07:58.089Z"
   },
   {
    "duration": 21,
    "start_time": "2024-07-25T23:07:58.135Z"
   },
   {
    "duration": 1542,
    "start_time": "2024-07-25T23:09:34.292Z"
   },
   {
    "duration": 1764,
    "start_time": "2024-07-25T23:12:47.525Z"
   },
   {
    "duration": 147,
    "start_time": "2024-07-25T23:18:43.392Z"
   },
   {
    "duration": 419,
    "start_time": "2024-07-25T23:27:20.466Z"
   },
   {
    "duration": 459,
    "start_time": "2024-07-25T23:28:31.039Z"
   },
   {
    "duration": 452,
    "start_time": "2024-07-25T23:28:38.522Z"
   },
   {
    "duration": 445,
    "start_time": "2024-07-25T23:29:20.065Z"
   },
   {
    "duration": 762,
    "start_time": "2024-07-25T23:29:56.107Z"
   },
   {
    "duration": 443,
    "start_time": "2024-07-25T23:30:02.892Z"
   },
   {
    "duration": 574,
    "start_time": "2024-07-25T23:30:19.253Z"
   },
   {
    "duration": 1270,
    "start_time": "2024-07-25T23:33:49.869Z"
   },
   {
    "duration": 462,
    "start_time": "2024-07-25T23:34:03.695Z"
   },
   {
    "duration": 872,
    "start_time": "2024-07-25T23:34:39.442Z"
   },
   {
    "duration": 1053,
    "start_time": "2024-07-25T23:37:10.899Z"
   },
   {
    "duration": 1277,
    "start_time": "2024-07-25T23:37:16.532Z"
   },
   {
    "duration": 1482,
    "start_time": "2024-07-25T23:38:23.453Z"
   },
   {
    "duration": 1976,
    "start_time": "2024-07-25T23:38:30.106Z"
   },
   {
    "duration": 1263,
    "start_time": "2024-07-25T23:42:10.229Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
